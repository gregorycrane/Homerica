{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from greek_accentuation.characters import *\n",
    "from greek_accentuation.accentuation import *\n",
    "from greek_accentuation.syllabify import *\n",
    "from greek_normalisation.normalise import Normaliser, Norm\n",
    "normalise = Normaliser().normalise\n",
    "witnesses = {}\n",
    "\n",
    "greek_upper = [\n",
    "    \"Α\", \"Β\", \"Γ\", \"Δ\", \"Ε\", \"Ζ\", \"Η\", \"Θ\",\n",
    "    \"Ι\", \"Κ\", \"Λ\", \"Μ\", \"Ν\", \"Ξ\", \"Ο\", \"Π\",\n",
    "    \"Ρ\", \"Σ\", \"Τ\", \"Υ\", \"Φ\", \"Χ\", \"Ψ\", \"Ω\"\n",
    "]\n",
    "\n",
    "def getpct(n1,n2):\n",
    "    return(re.sub('(\\.[0-9][0-9]).+','\\g<1>',str(n1/n2)))\n",
    "\n",
    "greek_lower = []\n",
    "for foo in greek_upper:\n",
    "    greek_lower.append(foo.lower())\n",
    "\n",
    "witnesses['Axt'] = 0\n",
    "witnesses['Antisthenes'] = 0\n",
    "\n",
    "witnesses['Aristarchs homerische textkritik I'] = 0\n",
    "witnesses['Aristarchs homerische textkritik II'] = 0\n",
    "\n",
    "witnesses['Passow'] = 0\n",
    "witnesses['sch. Eur. Hipp.'] = 0\n",
    "witnesses['Thom. M.'] = 0\n",
    "witnesses['Gent'] = 0\n",
    "witnesses['sch. Soph. Ai.'] = 0\n",
    "witnesses['Lennep'] = 0\n",
    "witnesses['sch. Soph.'] = 0\n",
    "witnesses['Dionys. Sid.'] = 0\n",
    "witnesses['sch. Nicand.'] = 0\n",
    "witnesses['Themistius'] = 0\n",
    "witnesses['Themistius or.'] = 0\n",
    "witnesses['Hesychius'] = 0\n",
    "witnesses['sch. Eur. Hipp.'] = 0\n",
    "witnesses['Cobet'] = 0\n",
    "witnesses['Apoll. pronom.'] = 0\n",
    "witnesses['Ahrens'] = 0\n",
    "witnesses['Christ'] = 0\n",
    "witnesses['Epigrammata ex lapidibus conlecta'] = 0\n",
    "\n",
    "witnesses['Callistratus'] = 0\n",
    "witnesses['Ernesti'] = 0\n",
    "witnesses['sch. L'] = 0\n",
    "witnesses['La Roche'] = 0\n",
    "witnesses['Ar'] = 0\n",
    "witnesses['Ai'] = 0\n",
    "witnesses['At'] = 0\n",
    "witnesses['Longinus'] = 0\n",
    "witnesses['Curtius'] = 0\n",
    "witnesses['Tyrannio'] = 0\n",
    "witnesses['Iulian'] = 0\n",
    "witnesses['Boissonade'] = 0\n",
    "witnesses['sch. G'] = 0\n",
    "witnesses['Cocondrius'] = 0\n",
    "witnesses['Stratonicus'] = 0\n",
    "witnesses['Nicanor'] = 0\n",
    "witnesses['Hermippus'] = 0\n",
    "witnesses['Friedlaender'] = 0\n",
    "witnesses['Nitzsch'] = 0\n",
    "witnesses['Niese'] = 0\n",
    "witnesses['sch. in Rhet. gr. VII'] = 0\n",
    "\n",
    "witnesses['Herodot.'] = 0\n",
    "witnesses['sch. Nicander Alexipharmaca'] = 0\n",
    "\n",
    "witnesses['Bekker'] = 0\n",
    "witnesses['Apoll. synt.'] = 0\n",
    "witnesses['Apoll. coni.'] = 0\n",
    "witnesses['sch. Eur. Tro.'] = 0\n",
    "witnesses['sch. Soph. OR.'] = 0\n",
    "witnesses['Peppmueller'] = 0\n",
    "witnesses['Themistius Rhetoricus'] = 0\n",
    "witnesses['Naber'] = 0\n",
    "witnesses['Duentzer'] = 0\n",
    "witnesses['Platt'] = 0\n",
    "witnesses['Welcker'] = 0\n",
    "witnesses['Wackernagel'] = 0\n",
    "witnesses['Alexio'] = 0\n",
    "witnesses['sch. Eur. Med.'] = 0\n",
    "\n",
    "witnesses['Moschopoulos'] = 0\n",
    "witnesses['Leeuw'] = 0\n",
    "witnesses['Ammonius'] = 0\n",
    "witnesses['Voss'] = 0\n",
    "witnesses['An. Ox.'] = 0\n",
    "witnesses['An. Par.'] = 0\n",
    "witnesses['Apoll. Soph.'] = 0\n",
    "witnesses['Aristarchus'] = 0\n",
    "witnesses['Aristarchea'] = 0\n",
    "witnesses['sch. Pind. Ol. VIII'] = 0\n",
    "witnesses['Clemens Alexandrinus protrepticus'] = 0\n",
    "\n",
    "\n",
    "witnesses['Ariston.'] = 0\n",
    "witnesses['Aristophanes'] = 0\n",
    "witnesses['Aristoteles'] = 0\n",
    "witnesses['Athenaeus'] = 0\n",
    "witnesses['Athenocles'] = 0\n",
    "witnesses['Thiersch'] = 0\n",
    "witnesses['Suda'] = 0\n",
    "witnesses['Grashof'] = 0\n",
    "witnesses['Ald.'] = 0\n",
    "witnesses['Monro'] = 0\n",
    "witnesses['Hoffmann'] = 0\n",
    "witnesses['Bentley'] = 0\n",
    "witnesses['Bothe'] = 0\n",
    "witnesses['Brandreth'] = 0\n",
    "witnesses['Chaeris'] = 0\n",
    "witnesses['Choeroboscus'] = 0\n",
    "witnesses['Anon. in Rhet. gr.'] = 0\n",
    "\n",
    "\n",
    "witnesses['Demetrius Ixion'] = 0\n",
    "witnesses['Did.'] = 0\n",
    "witnesses['Doederlein'] = 0\n",
    "\n",
    "witnesses['sch. Eur. Alc.'] = 0\n",
    "witnesses['Etymologicum Magnum'] = 0\n",
    "witnesses['Etymologicum Florentinum'] = 0\n",
    "witnesses['Etymologicum Gudianum'] = 0\n",
    "\n",
    "witnesses['Eust.'] = 0\n",
    "witnesses['Fick'] = 0\n",
    "witnesses['Giseke'] = 0\n",
    "witnesses['Hartel'] = 0\n",
    "\n",
    "witnesses['Haupt'] = 0\n",
    "witnesses['Heraclitus Allegoricus'] = 0\n",
    "\n",
    "witnesses['Herodian'] = 0\n",
    "witnesses['Herwerden'] = 0\n",
    "witnesses['Heyne'] = 0\n",
    "witnesses['Diogenes Laertius'] = 0\n",
    "witnesses['sch. Plato'] = 0\n",
    "witnesses['Bachmann'] = 0\n",
    "witnesses['Brugman'] = 0\n",
    "witnesses['Iulian'] = 0\n",
    "witnesses['Bekker, Anecdota Graeca'] = 0\n",
    "\n",
    "witnesses['Ioann. Alex.'] = 0\n",
    "witnesses['Kammer'] = 0\n",
    "witnesses['Leaf'] = 0\n",
    "witnesses['Ellendt'] = 0\n",
    "\n",
    "witnesses['Koechly'] = 0\n",
    "witnesses['lm-R'] = 0\n",
    "\n",
    "witnesses['Lehrs'] = 0\n",
    "witnesses['Lucian'] = 0\n",
    "\n",
    "\n",
    "witnesses['Macrob.'] = 0\n",
    "witnesses['Max. Tyr.'] = 0\n",
    "\n",
    "witnesses['Nicanor'] = 0\n",
    "witnesses['Nicole'] = 0\n",
    "\n",
    "\n",
    "witnesses['Plato'] = 0\n",
    "witnesses['Plut.'] = 0\n",
    "witnesses['Porph.'] = 0\n",
    "witnesses['Ptolemaeus Ascalonita'] = 0\n",
    "witnesses['Ptolemaeus'] = 0\n",
    "witnesses['Moschopoulos in Batrachomyomachia'] = 0\n",
    "\n",
    "witnesses['Rzach'] = 0\n",
    "witnesses['sch. A'] = 0\n",
    "witnesses['sch. At'] = 0\n",
    "witnesses['sch. Apoll. Rhod.'] = 0\n",
    "witnesses['sch. B'] = 0\n",
    "witnesses['sch. Dion. Thr'] = 0\n",
    "\n",
    "witnesses['sch. T'] = 0\n",
    "witnesses['Steph. B.'] = 0\n",
    "\n",
    "witnesses['Strab.'] = 0\n",
    "witnesses['Zenodotus'] = 0\n",
    "witnesses['Zonaras'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare book 6 in Fick with Ludwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tlg0012.tlg001.ludwich1902.06-txt.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e6360496fed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mludlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mficklines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tlg0012.tlg001.ludwich1902.06-txt.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0mgetlinewords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mludlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tlg0012.tlg001.ludwich1902.06-txt.xml'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from greek_accentuation.characters import *\n",
    "from greek_accentuation.accentuation import *\n",
    "from greek_accentuation.syllabify import *\n",
    "from greek_normalisation.normalise import Normaliser, Norm\n",
    "normalise = Normaliser().normalise\n",
    "\n",
    "prevlnum = 0\n",
    "curlnum = 0\n",
    "\n",
    "ludlines = {}\n",
    "ficklines = {}\n",
    "manualvariants = {\n",
    "    '60' : [\"ἒξ ἀπολοίατ\", \"ἒξ_ἀπολοίατ\" ],\n",
    "    '73' : [\"Ἄρευι φίλων\", \"Ἄρευι_φίλων\"],\n",
    "    '74' : [\"εἲς ἀνέβασαν\", \"εἲς_ἀνέβασαν\"],\n",
    "    '86' : [\"πόλιν δὲ\", \"πόλιν_δὲ\"],\n",
    "    '93' : [\"δύο καὶ δέκα\", \"δύο_καὶ_δέκα\"],\n",
    "    '274' : [\"δύο καὶ δέκα\", \"δύο_καὶ_δέκα\"],\n",
    "    '308' : [\"δύο καὶ δέκα\", \"δύο_καὶ_δέκα\"],\n",
    "    '243' : [\"τετύγμενον,\",\"τετύγμενον ,\"],\n",
    "    '250' : ['ἀλόχοισι\\.','ἀλόχοισι .'],\n",
    "    '265' : ['ἀλκῆς','om. ἀλκῆς'],\n",
    "    '363' : [\"σύ γ\",\"σύ_γ\"],\n",
    "    '365' : [\"οἶκον δ\", \"οἶκον_δ\"],\n",
    "    '367' : [\"τ᾽ οἷδ\",\"τ᾽_οἷδ\"],\n",
    "    '370' : [\"ἔϋ ναιετάοντας\",\"ἔϋ_ναιετάοντας\"],\n",
    "    '393' : ['Σκαίαις,','Σκαίαις ,','πεδίον δέ','πεδίον_δέ','πεδίονδε,','πεδίονδε ,'],\n",
    "    '395' : ['Ἀετίωνος,','Ἀετίωνος ,'],\n",
    "    '398' : ['χαλκοκορύσται·','χαλκοκορύσται ·'],\n",
    "    '399' : ['τᾶι γε καὶ','τᾶι_γε_καὶ'],\n",
    "    '404' : ['ἦ τοι',\"ἦ_τοι\"],\n",
    "    '414' : ['ἦ τοι',\"ἦ_τοι\"],\n",
    "    '412' : ['σύ γε','σύ_γε'],\n",
    "    '415' : [\"ἔϋ ναιετ\",\"ἔϋ_ναιετν\"],\n",
    "    '497' : [\"ἔϋ ναιετ\",\"ἔϋ_ναιετν\"],\n",
    "    '417' : [\"ἐξενάριξε,\",\"ἐξενάριξε ,\",'θύμωι,','θύμωι ,'],\n",
    "    '474' : ['γ᾽ ὃν','γ᾽_ὃν'],\n",
    "    '495' : [\"οἶκον δὲ\",\"οἶκον_δὲ\"],\n",
    "    '511' : ['τ᾽ ἤθεα','τ᾽_ἤθεα']\n",
    "}\n",
    "\n",
    "def setmanualvariants(lnum,l):\n",
    "    if(lnum in manualvariants):\n",
    "        starts = manualvariants[lnum][0]\n",
    "        ends = manualvariants[lnum][1]\n",
    "        \n",
    "        l = re.sub(starts,ends,l)\n",
    "        if(len(manualvariants[lnum]) > 2):\n",
    "            starts = manualvariants[lnum][2]\n",
    "            ends = manualvariants[lnum][3]\n",
    "        \n",
    "            l = re.sub(starts,ends,l)\n",
    "        if(len(manualvariants[lnum]) == 6):\n",
    "            starts = manualvariants[lnum][4]\n",
    "            ends = manualvariants[lnum][5]\n",
    "        \n",
    "            l = re.sub(starts,ends,l)\n",
    "    #l = re.sub('\\s*([,\\.;])',' \\g<1>',l)\n",
    "    #l = re.sub('\\s*(·)',' \\g<1>',l)\n",
    "          \n",
    "        #print(lnum,starts,ends,l)\n",
    "    return(l)\n",
    "\n",
    "def bareword(s):\n",
    "    noaccrdg = strip_accents(s)\n",
    "            \n",
    "    nodiacritrdg = re.sub('h','',debreath(noaccrdg).lower())\n",
    "    nodiacritrdg = re.sub('[ϝϜ]','',nodiacritrdg)\n",
    "    nodiacritrdg = re.sub('ῥ','ρ',nodiacritrdg)\n",
    "    nodiacritrdg = re.sub('η','α',nodiacritrdg)\n",
    "    nodiacritrdg = re.sub('ῳ','ωι',nodiacritrdg)\n",
    "    nodiacritrdg = re.sub('ᾳ','αι',nodiacritrdg)\n",
    "    nodiacritrdg = re.sub('ῃ','αι',nodiacritrdg)\n",
    "    nodiacritrdg = re.sub('ϋ','υ',nodiacritrdg)\n",
    "    nodiacritrdg = re.sub('ϊ','ι',nodiacritrdg)\n",
    "    nodiacritrdg = re.sub('νγ','γγ',nodiacritrdg)\n",
    "    \n",
    "\n",
    "    return(nodiacritrdg)\n",
    "\n",
    "\n",
    "def getlinewords(f,curdict):\n",
    "    for l in f:\n",
    "        l = re.sub('\\s+$','',l)\n",
    "        m = re.search('<l n=\"([^\"]+)\">',l)\n",
    "        if(not m):\n",
    "            continue\n",
    "        lnum = m[1]\n",
    "        l = re.sub('<l n=\"([^\"]+)\">','',l)\n",
    "        l = re.sub('</l>','',l)\n",
    "        l = setmanualvariants(lnum,l)\n",
    "        words = l.split()\n",
    "        ludlines[lnum] = []\n",
    "        for foo in words:\n",
    "            ludlines[lnum].append(re.sub('_', ' ',foo)) \n",
    "\n",
    "    #ludlines[lnum] = l.split()\n",
    "\n",
    "ludlines = {}\n",
    "ficklines = {}\n",
    "f = open('tlg0012.tlg001.ludwich1902.06-text.xml')\n",
    "getlinewords(f,ludlines)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
